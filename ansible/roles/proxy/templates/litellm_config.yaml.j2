# LiteLLM Configuration - Auto-generated by Ansible
# ZDR (Zero Data Retention) providers prioritized

model_list:
  # Default fast model - Groq Llama 4
  - model_name: default
    litellm_params:
      model: groq/llama-4-maverick-17b-128e-instruct
      api_key: os.environ/GROQ_API_KEY

  - model_name: fast
    litellm_params:
      model: groq/llama-4-maverick-17b-128e-instruct
      api_key: os.environ/GROQ_API_KEY

  # Together AI models (ZDR)
  - model_name: together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
    litellm_params:
      model: together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
      api_key: os.environ/TOGETHER_API_KEY

  - model_name: together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
    litellm_params:
      model: together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY

  - model_name: together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
    litellm_params:
      model: together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY

  # Groq models (fast inference)
  - model_name: groq/llama-4-maverick-17b-128e-instruct
    litellm_params:
      model: groq/llama-4-maverick-17b-128e-instruct
      api_key: os.environ/GROQ_API_KEY

  - model_name: groq/llama-3.3-70b-versatile
    litellm_params:
      model: groq/llama-3.3-70b-versatile
      api_key: os.environ/GROQ_API_KEY

  - model_name: groq/llama-3.1-8b-instant
    litellm_params:
      model: groq/llama-3.1-8b-instant
      api_key: os.environ/GROQ_API_KEY

litellm_settings:
  drop_params: true
  set_verbose: false
  num_retries: 2
  request_timeout: 120
  telemetry: false

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  disable_spend_logs: true  # ZDR compliance

# Custom callbacks for billing integration
callbacks:
  - hooks.billing_callback.billing_callback_instance
